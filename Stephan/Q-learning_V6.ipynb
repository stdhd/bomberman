{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# taler = 1\n",
    "spielfeld = np.zeros([5,5])\n",
    "spielfeld[0,:] = 2\n",
    "spielfeld[4,:] = 2\n",
    "spielfeld[:,0] = 2\n",
    "spielfeld[:,4] = 2\n",
    "\n",
    "spielfeld[3,3] = 1\n",
    "\n",
    "spielfeld = spielfeld.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = [1,1]\n",
    "learned = np.zeros([0,4])\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2, 2],\n",
       "       [2, 0, 0, 0, 2],\n",
       "       [2, 0, 0, 0, 2],\n",
       "       [2, 0, 0, 1, 2],\n",
       "       [2, 2, 2, 2, 2]])"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spielfeld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learned:\n",
      "[[ -1.8          0.           0.          -1.8       ]\n",
      " [ -1.8          0.           0.          -1.8       ]\n",
      " [  0.           0.          -1.8          0.        ]\n",
      " [ -1.8          0.           0.          -1.8       ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.          -1.8          0.          -1.8       ]\n",
      " [  0.           0.          -1.8        180.        ]\n",
      " [  0.          -5.59998033  -2.00000398   0.        ]\n",
      " [  0.           0.          -1.8          0.        ]\n",
      " [ -2.00000002  -2.          -3.99997815   0.        ]\n",
      " [  0.          -4.00016356  -2.          -2.        ]\n",
      " [ -1.9999998   -2.          -2.00017998  -2.        ]\n",
      " [  0.          -2.00002178   0.          -2.18018   ]\n",
      " [ -3.99979602   0.          -2.18324128  -2.        ]\n",
      " [ -2.00019962  -2.           0.          -4.00163544]\n",
      " [ -2.00180004   0.          -2.           0.        ]\n",
      " [ -2.0000036    0.           0.          -2.00000002]]\n",
      "observations:\n",
      "[[3. 2. 2. 0. 0.]\n",
      " [3. 2. 0. 0. 0.]\n",
      " [3. 0. 2. 0. 0.]\n",
      " [3. 0. 0. 0. 0.]\n",
      " [2. 0. 2. 2. 0.]\n",
      " [3. 2. 0. 0. 2.]\n",
      " [3. 0. 0. 1. 2.]\n",
      " [0. 0. 0. 2. 2.]\n",
      " [2. 0. 0. 2. 1.]\n",
      " [0. 0. 0. 2. 0.]\n",
      " [0. 0. 0. 0. 2.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 2.]\n",
      " [0. 0. 2. 0. 0.]\n",
      " [0. 2. 0. 0. 0.]\n",
      " [0. 0. 2. 2. 0.]\n",
      " [0. 2. 2. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "do_action(state, spielfeld, learned, epsilon)\n",
    "# 1. Richtung des nächsten Coins: (1,2,3,4:links,oben,rechts,unten)\n",
    "# 2.-5. Direkte Umgebung: (links, oben, rechts, unten; 0=frei, 1 = Coin, 2 = Wand)\n",
    "# 3. 0. 0. 1. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_action(state, spielfeld, learned, epsilon):\n",
    "    obs = np.zeros([0,5])\n",
    "    for i in range(1000):\n",
    "        # spielfeld[state[0], state[1]] = 2\n",
    "        actions = np.array([\"down\", \"up\", \"left\", \"right\"])\n",
    "        discount = 0.2\n",
    "        learning_rate = 0.9\n",
    "        n_state = [0,0]\n",
    "        if False:\n",
    "            print(\"+++++++++++++++++++\")\n",
    "        else:\n",
    "            indices = np.array([])\n",
    "            possible_actions = np.array([])\n",
    "            current_obs = get_observation(spielfeld,state[0],state[1])\n",
    "            # print(current_obs)\n",
    "            obs, index_current, learned = update_and_get_obs(obs, current_obs, learned)\n",
    "\n",
    "            if not state[0] == 1:\n",
    "                #darf nach oben gehen\n",
    "                new_obs = get_observation(spielfeld,state[0] - 1,state[1])\n",
    "                # print(new_obs)\n",
    "                obs, to_add, learned = update_and_get_obs(obs, new_obs, learned)\n",
    "                indices = np.append(indices,to_add)\n",
    "                possible_actions = np.append(possible_actions,[\"up\"])\n",
    "            if not state[0] == 3:\n",
    "                # darf nach unten gehen\n",
    "                new_obs = get_observation(spielfeld,state[0] + 1,state[1])\n",
    "                obs, to_add, learned = update_and_get_obs(obs, new_obs, learned)\n",
    "                indices = np.append(indices,to_add)\n",
    "                possible_actions = np.append(possible_actions,[\"down\"])\n",
    "            if not state[1] == 3:\n",
    "                # darf nach rechts gehen\n",
    "                new_obs = get_observation(spielfeld,state[0],state[1] + 1)\n",
    "                obs, to_add, learned = update_and_get_obs(obs, new_obs, learned)\n",
    "                indices = np.append(indices,to_add)\n",
    "                possible_actions = np.append(possible_actions,[\"right\"])\n",
    "            if not state[1] == 1:\n",
    "                # darf nach links gehen\n",
    "                new_obs = get_observation(spielfeld,state[0],state[1] - 1)\n",
    "                obs, to_add, learned = update_and_get_obs(obs, new_obs, learned)\n",
    "                indices = np.append(indices,to_add)\n",
    "                possible_actions = np.append(possible_actions,[\"left\"])\n",
    "\n",
    "            indices = indices.astype(int)\n",
    "            # Hole Werte der möglichen Folgezustände\n",
    "            #print(obs)\n",
    "            #print(indices)\n",
    "            #print(\"x\")\n",
    "            values = learned[indices,:]\n",
    "            #print(values)\n",
    "            # print(learned)\n",
    "           # optima = np.argmax(values.flatten(), axis = 0)\n",
    "            if epsilon > uniform(0,1):\n",
    "                # epsilon -= 0.001\n",
    "                # Random Choice\n",
    "                # print(indices)\n",
    "                # print(\"RANDOM\")\n",
    "                b = values.flatten()\n",
    "                # print(b)\n",
    "                optima = np.random.choice(np.flatnonzero(b))\n",
    "                best_choice = possible_actions[optima // 4]\n",
    "                best_value = values.flatten()[optima]\n",
    "            else:\n",
    "                b = values.flatten()\n",
    "                # print(b)\n",
    "                optima = np.random.choice(np.flatnonzero(b == b.max()))\n",
    "                best_choice = possible_actions[optima // 4]\n",
    "                best_value = values.flatten()[optima]\n",
    "           # print(best_choice, state)\n",
    "\n",
    "            # get Reward\n",
    "            if(best_choice == \"down\"):\n",
    "                action_index = 0\n",
    "                n_state[0] = state[0] + 1\n",
    "                n_state[1] = state[1]\n",
    "            elif(best_choice == \"up\"):\n",
    "                action_index = 1\n",
    "                n_state[0] = state[0] - 1\n",
    "                n_state[1] = state[1]\n",
    "            elif(best_choice == \"left\"):\n",
    "                action_index = 2\n",
    "                n_state[0] = state[0]\n",
    "                n_state[1] = state[1] - 1\n",
    "            elif(best_choice == \"right\"):\n",
    "                action_index = 3\n",
    "                n_state[0] = state[0]\n",
    "                n_state[1] = state[1] + 1\n",
    "                \n",
    "            reward, spielfeld = get_reward(state,spielfeld,best_choice)\n",
    "            learned[index_current, action_index] = (1-learning_rate) * learned[index_current,action_index] + learning_rate * (best_value + discount * reward)\n",
    "            state = n_state\n",
    "    print(\"learned:\")\n",
    "    print(learned)\n",
    "    print(\"observations:\")\n",
    "    print(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reward(state,spielfeld,action):\n",
    "    x,y = 0,0\n",
    "    if action == \"left\":\n",
    "        x = -1\n",
    "    if action == \"right\":\n",
    "        x = 1\n",
    "    if action == \"down\":\n",
    "        y = 1\n",
    "    if action == \"up\":\n",
    "        y = -1\n",
    "        \n",
    "    x +=state[1]    \n",
    "    y +=state[0]\n",
    "    if spielfeld[y,x] == 1:\n",
    "        # collect coin\n",
    "        spielfeld[y,x] = 0\n",
    "        return 1000, spielfeld\n",
    "    else:\n",
    "        return -10, spielfeld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation(spielfeld, y, x):\n",
    "    # Suche den Coin, der am nächsten ist (manhattan distance)\n",
    "    coinsY, coinsX = np.where(spielfeld == 1)\n",
    "    distancesY = np.abs(coinsY - y)\n",
    "    distancesX = np.abs(coinsX - x)\n",
    "    observation = np.array([0, 0,0,0,0]) \n",
    "    # 1. Richtung des nächsten Coins: (1,2,3,4:links,oben,rechts,unten)\n",
    "    # 2. Direkte Umgebung: (links, oben, rechts, unten; 0=frei, 1 = Coin, 2 = Wand)\n",
    " \n",
    "    if not distancesY.shape[0] == 0:\n",
    "        distances = distancesY + distancesX\n",
    "        coinY = coinsY[np.argmin(distances)]\n",
    "        coinX = coinsX[np.argmin(distances)]\n",
    "        # setze observation flags:\n",
    "        if coinX < x:\n",
    "            observation[0] = 1\n",
    "        elif coinX > x:\n",
    "            observation[0] = 3\n",
    "        elif coinY > y:\n",
    "            observation[0] = 2\n",
    "        elif coinY < y:\n",
    "            observation[0] = 4\n",
    "    \n",
    "    \n",
    "    observation[1] = spielfeld[y, x - 1]\n",
    "    observation[2] = spielfeld[y - 1, x]\n",
    "    observation[3] = spielfeld[y, x + 1]\n",
    "    observation[4] = spielfeld[y + 1, x]\n",
    "    \n",
    "    return observation\n",
    "\n",
    "def update_and_get_obs(db, new_obs, learned):\n",
    "    temp = -1\n",
    "    # print(\" \")\n",
    "    # print(\"----\")\n",
    "    #print(db)\n",
    "    #print(new_obs)\n",
    "    #print(\"----\")\n",
    "    for i in range(db.shape[0]):\n",
    "        #print(db[i])\n",
    "        #print(\"==\")\n",
    "        #print(new_obs)\n",
    "        if np.array_equal(db[i], new_obs):\n",
    "            # print(\"old\")\n",
    "            return db, i, learned\n",
    "    # print(\"new\")\n",
    "    db = np.append(db,np.array([new_obs]), axis = 0)\n",
    "    learned = np.append(learned, np.zeros([1,learned.shape[1]]), axis = 0)\n",
    "    # print(db)\n",
    "    return db, (db.shape[0] - 1), learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = np.array([1,6,8])\n",
    "#db = np.array([[1,3,2],[4,455,6]])\n",
    "#learned = np.array([[2,3,6,6],[4,3,6,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1   3   2]\n",
      " [  4 455   6]\n",
      " [  2   6   8]]\n",
      "[1 6 8]\n",
      "new\n"
     ]
    }
   ],
   "source": [
    "db, y, learned = update_and_get_obs(db, new,learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   3,   2],\n",
       "       [  4, 455,   6],\n",
       "       [  2,   6,   8],\n",
       "       [  1,   6,   8]])"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 6., 6.],\n",
       "       [4., 3., 6., 6.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
