{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import *\n",
    "import matplotlib.pyplot as plt\n",
    "from indices import *\n",
    "from create_observation_V6 import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_train_from_games(reader_path, writer_path):\n",
    "    \"\"\"\n",
    "    Reads all json-files from reader_path\n",
    "    Trains Q table\n",
    "    Writes resulting Q table to writer_path\n",
    "    TODO: iterate over games = state files\n",
    "    \"\"\"\n",
    "    AGENTS_COUNT = 4\n",
    "    OBSERVATION_LENGTH = 8\n",
    "    ACTIONS_COUNT = = 4 \n",
    "    \n",
    "    daten = np.load(reader_path)\n",
    "    learned = np.zeros([daten,4])\n",
    "    obs = np.zeros([0, OBSERVATION_LENGTH])\n",
    "    \n",
    "    for i in range(daten.shape[0]):\n",
    "        observation_db, action_db, reward_db = create_observation_vectors(daten[i], window_radius=2, AGENTS_COUNT)\n",
    "        for j in range(AGENTS_COUNT):\n",
    "            learned, obs = do_action(learned, obs, 0.8, 0.7, observation_db[j], action_db[j], reward_db[j])\n",
    "        \n",
    "    return obs, learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_action(learned, obs, learning_rate, discount, observation_db, action_db, reward_db):\n",
    "    last_action_index = -1\n",
    "    last_index = -1\n",
    "    last_reward = -1\n",
    "    for i in range(observation_db.shape[0]):\n",
    "       \n",
    "        current_obs = observation_db[i]\n",
    "        obs, index_current, learned = update_and_get_obs(obs, current_obs, learned)\n",
    "        \n",
    "        choice = action_db[i]\n",
    "        \n",
    "        my_best_value = np.max(learned[index_current])\n",
    "        n_state = get_following_state(state, spielfeld, actions[choice], actions, True)\n",
    "        if (not last_index == -1):\n",
    "            learned[last_index, last_action_index] = (1-learning_rate) * learned[last_index, last_action_index] + learning_rate * (last_reward + discount * my_best_value)\n",
    "            \n",
    "        last_reward = reward_db[i]\n",
    "        last_action_index = choice\n",
    "        last_index = index_current\n",
    "                       \n",
    "    reihe = np.append(reihe, np.array([reihenvalue]))\n",
    "    return learned, obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_and_get_obs(db, new_obs, learned):\n",
    "    temp = -1\n",
    "    for i in range(db.shape[0]):\n",
    "        if np.array_equal(db[i], new_obs):\n",
    "            return db, i, learned\n",
    "    db = np.append(db,np.array([new_obs]), axis = 0)\n",
    "    learned = np.append(learned, np.zeros([1,learned.shape[1]]), axis = 0)\n",
    "    return db, (db.shape[0] - 1), learned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
