{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(state, spielfeld, learned, epsilon, gamma, alpha, rounds):\n",
    "    not_found = True\n",
    "#     for i in range(rounds):\n",
    "    while(not_found):\n",
    "        n_state = [0,0]\n",
    "        indices = np.array([])\n",
    "        possible_actions = np.array([])\n",
    "        index_current = state[0]*5 + state[1]\n",
    "        if not state[0] == 4:\n",
    "            # darf nach unten gehen\n",
    "            indices = np.append(indices,[index_current + 5])\n",
    "            possible_actions = np.append(possible_actions,[\"down\"])\n",
    "        if not state[0] == 0:\n",
    "            #darf nach oben gehen\n",
    "            indices = np.append(indices,[index_current - 5])\n",
    "            possible_actions = np.append(possible_actions,[\"up\"])\n",
    "        if not state[1] == 0:\n",
    "            # darf nach links gehen\n",
    "            indices = np.append(indices,[index_current - 1])\n",
    "            possible_actions = np.append(possible_actions,[\"left\"])\n",
    "        if not state[1] == 4:\n",
    "            # darf nach rechts gehen\n",
    "            indices = np.append(indices,[index_current + 1])\n",
    "            possible_actions = np.append(possible_actions,[\"right\"])\n",
    "        \n",
    "        if epsilon > uniform(0,1):\n",
    "            # Random Choice\n",
    "            choice = np.random.choice(possible_actions)\n",
    "            print(\"Random action:\", state, choice)\n",
    "#             TODO Best value for update\n",
    "        else:\n",
    "            # Hole Werte der möglichen Folgezustände\n",
    "            values = learned[indices.astype(int),:]\n",
    "            b = values.flatten()\n",
    "            optima = np.random.choice(np.flatnonzero(b == b.max()))            \n",
    "            choice = possible_actions[optima // 4]\n",
    "            best_value = values.flatten()[optima]\n",
    "            print(state, choice)\n",
    "\n",
    "        # get Reward\n",
    "        if(choice == \"down\"):\n",
    "            action_index = 0\n",
    "            n_state[0] = state[0] + 1\n",
    "            n_state[1] = state[1]\n",
    "        elif(choice == \"up\"):\n",
    "            action_index = 1\n",
    "            n_state[0] = state[0] - 1\n",
    "            n_state[1] = state[1]\n",
    "        elif(choice == \"left\"):\n",
    "            action_index = 2\n",
    "            n_state[0] = state[0]\n",
    "            n_state[1] = state[1] - 1\n",
    "        elif(choice == \"right\"):\n",
    "            action_index = 3\n",
    "            n_state[0] = state[0]\n",
    "            n_state[1] = state[1] + 1\n",
    "\n",
    "        learned[index_current, action_index] = learned[index_current,action_index] \\\n",
    "             + alpha * (get_reward(state,spielfeld,choice) + gamma * best_value - learned[index_current,action_index])\n",
    "\n",
    "        state = n_state\n",
    "        if state == [4,4]:\n",
    "            state = [0,0]\n",
    "            learned[24, :] = learned[24, :] + np.max(learned[23, :]) + np.max(learned[19, :])\n",
    "            not_found = False\n",
    "            print(\"-----------found!\")\n",
    "    print(\"-------- Down -------- Up -------- Left -------- Right\")\n",
    "    print(learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(state,spielfeld,action):\n",
    "    x,y = 0,0\n",
    "    if action == \"left\":\n",
    "        x = -1\n",
    "    elif action == \"right\":\n",
    "        x = 1\n",
    "    elif action == \"down\":\n",
    "        y = 1\n",
    "    elif action == \"up\":\n",
    "        y = -1\n",
    "        \n",
    "    x +=state[1]    \n",
    "    y +=state[0]\n",
    "#   1 = Coin, 2 = Enemy\n",
    "    if spielfeld[y,x] == 1:\n",
    "        return 10\n",
    "    elif spielfeld[y,x] == 2:\n",
    "        return -50\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(state, spielfeld, learned):\n",
    "    n_state = [0,0]\n",
    "    for i in range(24):    \n",
    "        index_current = state[0]*5 + state[1]\n",
    "        action_index = np.array([])\n",
    "        possible_actions = np.array([])\n",
    "\n",
    "        if not state[0] == 4:\n",
    "            # darf nach unten gehen\n",
    "            possible_actions = np.append(possible_actions,[\"down\"])\n",
    "            action_index = np.append(action_index, 0)\n",
    "        if not state[0] == 0:\n",
    "            #darf nach oben gehen\n",
    "            possible_actions = np.append(possible_actions,[\"up\"])\n",
    "            action_index = np.append(action_index, 1)\n",
    "        if not state[1] == 0:\n",
    "            # darf nach links gehen\n",
    "            possible_actions = np.append(possible_actions,[\"left\"])\n",
    "            action_index = np.append(action_index, 2)\n",
    "        if not state[1] == 4:\n",
    "            # darf nach rechts gehen\n",
    "            possible_actions = np.append(possible_actions,[\"right\"])\n",
    "            action_index = np.append(action_index, 3)\n",
    "\n",
    "        # Hole maximalen Wert aus learned\n",
    "        chosen_action_index = np.argmax(learned[index_current, action_index.astype(int)])\n",
    "        best_choice = possible_actions[chosen_action_index]\n",
    "        print(state, best_choice)\n",
    "\n",
    "        # get Reward\n",
    "        if(best_choice == \"down\"):\n",
    "            n_state[0] = state[0] + 1\n",
    "            n_state[1] = state[1]\n",
    "        elif(best_choice == \"up\"):\n",
    "            n_state[0] = state[0] - 1\n",
    "            n_state[1] = state[1]\n",
    "        elif(best_choice == \"left\"):\n",
    "            n_state[0] = state[0]\n",
    "            n_state[1] = state[1] - 1\n",
    "        elif(best_choice == \"right\"):\n",
    "            n_state[0] = state[0]\n",
    "            n_state[1] = state[1] + 1\n",
    "\n",
    "        state = n_state\n",
    "        if state == [4,4]:\n",
    "            state = [0,0]\n",
    "            learned[24, :] = learned[24, :] + np.max([learned[23, :], learned[19, :]])\n",
    "            print(\"-----------found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]\n",
      " [2 2 2 0 2]\n",
      " [0 0 0 0 0]\n",
      " [2 2 2 0 2]\n",
      " [0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Coin = 1, Enemy = 2\n",
    "spielfeld = np.zeros([5,5])\n",
    "spielfeld[4,4] = 1\n",
    "# spielfeld[2,0] = 1\n",
    "spielfeld[1,0:3] = 2\n",
    "spielfeld[1,4] = 2\n",
    "spielfeld[3,0:3] = 2\n",
    "spielfeld[3,4] = 2\n",
    "spielfeld = spielfeld.astype(int)\n",
    "print(spielfeld)\n",
    "\n",
    "state = [0,0]\n",
    "learned = np.zeros([25,4])\n",
    "learned[24,:] = 1\n",
    "learned[24,:] = 1\n",
    "epsilon = 0.2\n",
    "gamma = 0.3\n",
    "alpha = 0.5\n",
    "rounds = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-2-28a62573160f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-28a62573160f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    train(state, spielfeld, learned, epsilon=0.2, gamma, alpha, rounds)\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "train(state, spielfeld, learned, epsilon, gamma, alpha, rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] right\n",
      "[0, 1] left\n",
      "[0, 0] right\n",
      "[0, 1] left\n",
      "[0, 0] right\n",
      "[0, 1] left\n",
      "[0, 0] right\n",
      "[0, 1] left\n",
      "[0, 0] right\n",
      "[0, 1] left\n",
      "[0, 0] right\n",
      "[0, 1] left\n",
      "[0, 0] right\n",
      "[0, 1] left\n",
      "[0, 0] right\n",
      "[0, 1] left\n",
      "[0, 0] right\n",
      "[0, 1] left\n",
      "[0, 0] right\n",
      "[0, 1] left\n",
      "[0, 0] right\n",
      "[0, 1] left\n",
      "[0, 0] right\n",
      "[0, 1] left\n"
     ]
    }
   ],
   "source": [
    "test(state,spielfeld,learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[False  True False False False False False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([-1,0,0,-1,0,0,-1])\n",
    "print(b == b.max())\n",
    "np.flatnonzero(b == b.max())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.69\n",
      "[array([0., 0., 0., 0.]), array([23.69,  0.  ,  0.  ,  0.  ])]\n"
     ]
    }
   ],
   "source": [
    "print(np.max([learned[23, :], learned[19, :]]))\n",
    "print([learned[23, :], learned[19, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.99999999e+01,  0.00000000e+00,  0.00000000e+00,\n",
       "        -1.00000000e+00],\n",
       "       [-1.80000000e+01,  0.00000000e+00, -9.99999743e-01,\n",
       "        -1.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00, -9.99999972e-01,\n",
       "        -9.99998084e-01],\n",
       "       [-5.90400000e-01,  0.00000000e+00, -9.99009648e-01,\n",
       "        -9.99867077e-01],\n",
       "       [-2.53472307e+01,  0.00000000e+00, -9.64815628e-01,\n",
       "         0.00000000e+00],\n",
       "       [-9.99740385e-01, -9.99999933e-01,  0.00000000e+00,\n",
       "        -3.68928000e+01],\n",
       "       [-2.00000000e-01, -2.00000000e-01, -3.68928000e+01,\n",
       "        -1.80000000e+01],\n",
       "       [-2.00000000e-01, -2.00000000e-01, -1.00000000e+01,\n",
       "        -2.00000000e-01],\n",
       "       [-3.60000000e-01, -2.00000000e-01, -1.00000000e+01,\n",
       "        -2.44000000e+01],\n",
       "       [ 2.22177131e+02, -7.37856000e-01, -2.00000000e-01,\n",
       "         0.00000000e+00],\n",
       "       [-4.88741001e+01, -4.97048521e+01,  0.00000000e+00,\n",
       "        -5.90400000e-01],\n",
       "       [-1.80000000e+01, -1.00000000e+01, -2.00000000e-01,\n",
       "        -2.00000000e-01],\n",
       "       [-1.00000000e+01, -1.00000000e+01,  0.00000000e+00,\n",
       "        -2.00000000e-01],\n",
       "       [-3.60000000e-01, -2.00000000e-01, -2.00000000e-01,\n",
       "         0.00000000e+00],\n",
       "       [ 1.76795350e+03,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [-9.31280523e-01, -7.37856000e-01,  0.00000000e+00,\n",
       "        -3.95142400e+01],\n",
       "       [-3.64651496e-01,  0.00000000e+00, -2.44000000e+01,\n",
       "        -2.44000000e+01],\n",
       "       [-1.57571476e-01,  0.00000000e+00, -1.00000000e+01,\n",
       "        -3.60000000e-01],\n",
       "       [ 1.21529086e+00, -2.00000000e-01,  0.00000000e+00,\n",
       "        -1.00000000e+01],\n",
       "       [ 1.38681969e+04,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00, -3.36160000e+01,  0.00000000e+00,\n",
       "        -8.37710293e-01],\n",
       "       [ 0.00000000e+00, -1.00000000e+01, -3.60000000e-01,\n",
       "         7.83210429e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00, -2.00000000e-01,\n",
       "         1.48813067e+02],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         5.46885689e+03],\n",
       "       [ 1.08177538e+05,  1.08177538e+05,  1.08177538e+05,\n",
       "         1.08177538e+05]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
